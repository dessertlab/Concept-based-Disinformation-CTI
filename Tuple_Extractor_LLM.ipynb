{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Leox48/Disinformation-Threat-Intelligence/blob/main/Tuplet_Extractor_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhEDYalWkv7b"
   },
   "source": [
    "## Step 1: Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VuenKPqoNfS",
    "outputId": "92ec7007-c0ea-4fef-85ec-5acc309c3bf2"
   },
   "outputs": [],
   "source": [
    "!python -V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nj8FZCXshH-Y",
    "outputId": "9d51b09a-4356-49b0-c20e-1c5f1cc43bf8"
   },
   "outputs": [],
   "source": [
    "!nvcc --version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-oKv5ARNT9a"
   },
   "source": [
    "`cu121`: CUDA 12.1 - `cu122`: CUDA 12.2 - `cu123`: CUDA 12.3 - `cu124`: CUDA 12.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X15zY5debUpP",
    "outputId": "6e1e6da2-779a-4834-be74-3a4b8ec237d6"
   },
   "outputs": [],
   "source": [
    "\n",
    "!set CMAKE_ARGS=-DGGML_CUDA=on\n",
    "!set FORCE_CMAKE=1\n",
    "\n",
    "!python -m pip install llama-cpp-python --prefer-binary --extra-index-url=https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/AVX2/cu122 --force-reinstall\n",
    "\n",
    "\n",
    "!pip install torch==2.3.0 torchvision torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efJ_g2etSvLD"
   },
   "source": [
    "## Step 2: Download LLM from HuggingFace\n",
    "\n",
    "Use the \"hf_hub_download\" function to download models on huggingface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpXQGhHlij6q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "fe50d2e2c8804b39a7621c70e8e9f300",
      "34024d889142412bb0423edbe95485c8",
      "01d042efa4bb4275b044c101d641416c",
      "5bd60f27249540629759b87e9af26f18",
      "301ae1e92ed24dd4b1f8c6961e00c0ec",
      "3a5b2867feff496980da408158ec95dc",
      "2067567d3d914860b5ae4135939bc63d",
      "13cc8ff94eff4db48bf41c90e035f300",
      "5706239284534b289104b82246c1edf5",
      "d990da007ea34af1a53ececfbba4d1d3",
      "9bb8726294894cc38468132b7013832d"
     ]
    },
    "id": "WsYot3Rz1NVf",
    "outputId": "e62b4948-8eec-4800-b235-01f53f5e2c43"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_name = \"MaziyarPanahi/Llama-3-8B-Instruct-v0.10-GGUF\"\n",
    "\n",
    "#Quantizzazione 1\n",
    "#model_file = \"Llama-3-8B-Instruct-v0.10.Q4_K_M.gguf\" # this is the specific model file we'll use in this example. It's a 4-bit quant, but other levels of quantization are available in the model repo if preferred\n",
    "\n",
    "#Quantizzazione 2\n",
    "# model_file = \"Llama-3-8B-Instruct-v0.10.Q5_K_M.gguf\"\n",
    "\n",
    "#Quantizzazione 3\n",
    "#model_file = \"Llama-3-8B-Instruct-v0.10.Q8_0.gguf\"\n",
    "\n",
    "model_path = hf_hub_download(\n",
    "    model_name,\n",
    "    filename=model_file,\n",
    "    local_dir='models/',\n",
    "    )\n",
    "\n",
    "print(\"My model path:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0Xn9dRQMEvW"
   },
   "outputs": [],
   "source": [
    "del llm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFMXgvWzckbU"
   },
   "source": [
    "Note that BLAS = 1 means GPU is enabled:\n",
    "*   AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4GldNtm_s-P"
   },
   "source": [
    "## Step 3: LLM usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBMlNefW2qnq"
   },
   "source": [
    "####Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0_onscHeKt4",
    "outputId": "9b3ec268-dea7-4e9e-8a2b-501b604a509f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/content/DisinformNews Dataset.csv')\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VncP0-XokqtB"
   },
   "outputs": [],
   "source": [
    "# URL , TITOLO, SOURCE, TESTO, CAMPAGNA , THREAT ACTOR, TIPO\n",
    "colonna_id= df['ID']\n",
    "colonna_url = df['URL']\n",
    "colonna_titolo = df['TITOLO']\n",
    "colonna_source = df['SOURCE']\n",
    "colonna_testo = df['TESTO']\n",
    "colonna_campagna= df['CAMPAGNA']\n",
    "colonna_threat_actor = df['THREAT ACTOR']\n",
    "colonna_tipo = df['TIPO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIJAgUxHvyfj",
    "outputId": "1f06861f-7662-4c79-bd77-8238a36cff78"
   },
   "outputs": [],
   "source": [
    "print(colonna_testo[0])\n",
    "print(len(colonna_testo[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqeh1Aej6BO6"
   },
   "source": [
    "####Setup temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dK8lgU85hM-A"
   },
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache() # Clear GPU cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwVgw5ueul6l"
   },
   "source": [
    "**Run Temperature = 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSyxPuAXgfut"
   },
   "outputs": [],
   "source": [
    "def model_run(user_input):\n",
    "    \n",
    "    stop_sequence = [\"##END LIST##\",\"#END LIST#\",\"END LIST\"] \n",
    "\n",
    "    output = llm.create_chat_completion(\n",
    "        messages= [\n",
    "            {\"role\": \"system\", \"content\": \"You are a natural language processing expert specialized in analyzing textual data and extracting structured information.\"},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        top_p=0.95,\n",
    "        stop=stop_sequence\n",
    "    )\n",
    "\n",
    "    return output['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2nKlWPv0iI0"
   },
   "source": [
    "**Run Temperature = 0.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LE-psjH0k95"
   },
   "outputs": [],
   "source": [
    "def model_run(user_input):\n",
    "   \n",
    "    stop_sequence = [\"##END LIST##\",\"#END LIST#\",\"END LIST\"]\n",
    "\n",
    "    output = llm.create_chat_completion(\n",
    "        messages= [\n",
    "            {\"role\": \"system\", \"content\": \"You are a natural language processing expert specialized in analyzing textual data and extracting structured information.\"},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        top_p=0.95,\n",
    "        stop=stop_sequence\n",
    "    )\n",
    "\n",
    "    return output['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agYdcjGgAevP"
   },
   "source": [
    "**Run Temperature = 0.6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QP2s4AyAdbw"
   },
   "outputs": [],
   "source": [
    "def model_run(user_input):\n",
    "\n",
    "    stop_sequence = [\"##END LIST##\",\"#END LIST#\",\"END LIST\"]\n",
    "\n",
    "    output = llm.create_chat_completion(\n",
    "        messages= [\n",
    "            {\"role\": \"system\", \"content\": \"You are a natural language processing expert specialized in analyzing textual data and extracting structured information.\"},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ],\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "        stop=stop_sequence\n",
    "    )\n",
    "\n",
    "    return output['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUeUls9XBS1v"
   },
   "source": [
    "####Tuple extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EfB8cSiuzuN"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_tuples(text):\n",
    "    \n",
    "    before_note = text.split(\"##END LIST## (1)\")[0]\n",
    "\n",
    "    pattern = r'\\d*\\.*\\s*(.*? - .*? - .*?)\\n'\n",
    "\n",
    "    matches = re.findall(pattern, before_note)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IY3ks3DJejoa",
    "outputId": "7c4e03af-9384-4e25-8374-8ca7271af046"
   },
   "outputs": [],
   "source": [
    "user_input = f'''Read the following text and identify all the tuples in the subject-verb-object form. The tuples should reflect the main actions and relationships between the entities mentioned in the text. Follow these steps:\n",
    "\n",
    "              Your task is to identify subject-relation-object relationships from the input text, which represent key actions and relationships between entities. These triples will be used for structured representation of fake news articles.\n",
    "              Subject-relation-object relationships capture the fundamental structure of actions and relationships described in a sentence. In these relationships, the subject represents the entity performing an action, the verb describes the action or relationship, and the object represents the entity affected by the action. Identifying these relationships helps in organizing unstructured textual data into a structured format, enabling easier analysis and interpretation.\n",
    "\n",
    "\n",
    "              Read the following text and identify all the tuples in the subject-verb-object form. The tuples should reflect the main actions and relationships between the entities mentioned in the text. Follow these steps:\n",
    "              Identify the subject of the action.\n",
    "              Identify the verb that describes the action or relationship.\n",
    "              Identify the object or destination of the action.\n",
    "              Return the tuples in this format: Subject - Relation - Object. At the end of the process, print ''END LIST'' to indicate the conclusion of the extraction.\n",
    "\n",
    "              Example:\n",
    "              Text: 'John gave a book to Mary.'\n",
    "              Tuple: 'John - gave - a book to Mary'\n",
    "\n",
    "              Apply this method to the following text:, {colonna_testo[9]} '''\n",
    "\n",
    "response = model_run(user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9OCMcus9PTh",
    "outputId": "7448cc25-95a0-45df-ca83-11d5af89553f"
   },
   "outputs": [],
   "source": [
    "tuples = extract_tuples(response)\n",
    "print(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKtGNF3nRG4B",
    "outputId": "a58bc862-1f32-4c05-f1f8-9364a7013e61"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(10):\n",
    "\n",
    "  torch.cuda.empty_cache() \n",
    "  user_input = f'''Read the following text and identify all the tuples in the subject-verb-object form. The tuples should reflect the main actions and relationships between the entities mentioned in the text. Follow these steps:\n",
    "\n",
    "              Your task is to identify subject-relation-object relationships from the input text, which represent key actions and relationships between entities. These triples will be used for structured representation of fake news articles.\n",
    "              Subject-relation-object relationships capture the fundamental structure of actions and relationships described in a sentence. In these relationships, the subject represents the entity performing an action, the verb describes the action or relationship, and the object represents the entity affected by the action. Identifying these relationships helps in organizing unstructured textual data into a structured format, enabling easier analysis and interpretation.\n",
    "\n",
    "\n",
    "              Read the following text and identify all the tuples in the subject-verb-object form. The tuples should reflect the main actions and relationships between the entities mentioned in the text. Follow these steps:\n",
    "              Identify the subject of the action.\n",
    "              Identify the verb that describes the action or relationship.\n",
    "              Identify the object or destination of the action.\n",
    "              Return the tuples in this format: Subject - Relation - Object. At the end of the process, print ''END LIST'' to indicate the conclusion of the extraction.\n",
    "\n",
    "              Example:\n",
    "              Text: 'John gave a book to Mary.'\n",
    "              Tuple: 'John - gave - a book to Mary'\n",
    "\n",
    "              Apply this method to the following text:, {colonna_testo[i]} '''\n",
    "\n",
    "\n",
    " \n",
    "  response = model_run(user_input)\n",
    "  print(response)\n",
    "  print(\"-----------------------FINE--------------------------------------\")\n",
    " \n",
    "  tuples = extract_tuples(response)\n",
    "\n",
    "  if i == 0:\n",
    "    \n",
    "    df_tuple = pd.DataFrame(tuples, columns=['TUPLA'])\n",
    "    \n",
    "    df_tuple['ID ARTICOLO'] = colonna_id[i]\n",
    "    df_tuple['CAMPAGNA'] = colonna_campagna[i]\n",
    "  else:\n",
    "    \n",
    "    df_temp = pd.DataFrame({'TUPLA': tuples, 'ID ARTICOLO': colonna_id[i], 'CAMPAGNA': colonna_campagna[i]})\n",
    "    \n",
    "    df_tuple = pd.concat([df_tuple, df_temp], ignore_index=True)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "runtime = end_time - start_time\n",
    "print(\"response run time is: \", runtime)\n",
    "print(df_tuple.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wS4JrU-RrtH",
    "outputId": "7ba298f6-b6e8-4c38-c716-69fbde7c6687"
   },
   "outputs": [],
   "source": [
    "df_tuple.to_csv('TuplesExtracted_Q8_06TEMP.csv', index=False)\n",
    "print(runtime)\n",
    "print(\"File Excel creato con successo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZYg7oi2vPuU"
   },
   "outputs": [],
   "source": [
    "RT_Q5KM_0TEMP=371.50677728652954\n",
    "RT_Q5KM_03TEMP=385.1130666732788\n",
    "RT_Q5KM_06TEMP=394.9632875919342\n",
    "RT_Q8_0TEMP=340.24108028411865\n",
    "RT_Q8_03TEMP= 390.331839799881\n",
    "RT_Q8_06TEMP= 388.83690667152405"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01d042efa4bb4275b044c101d641416c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13cc8ff94eff4db48bf41c90e035f300",
      "max": 8540770944,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5706239284534b289104b82246c1edf5",
      "value": 8540770944
     }
    },
    "13cc8ff94eff4db48bf41c90e035f300": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2067567d3d914860b5ae4135939bc63d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "301ae1e92ed24dd4b1f8c6961e00c0ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34024d889142412bb0423edbe95485c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a5b2867feff496980da408158ec95dc",
      "placeholder": "​",
      "style": "IPY_MODEL_2067567d3d914860b5ae4135939bc63d",
      "value": "Llama-3-8B-Instruct-v0.10.Q8_0.gguf: 100%"
     }
    },
    "3a5b2867feff496980da408158ec95dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5706239284534b289104b82246c1edf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5bd60f27249540629759b87e9af26f18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d990da007ea34af1a53ececfbba4d1d3",
      "placeholder": "​",
      "style": "IPY_MODEL_9bb8726294894cc38468132b7013832d",
      "value": " 8.54G/8.54G [03:17&lt;00:00, 31.5MB/s]"
     }
    },
    "9bb8726294894cc38468132b7013832d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d990da007ea34af1a53ececfbba4d1d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe50d2e2c8804b39a7621c70e8e9f300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34024d889142412bb0423edbe95485c8",
       "IPY_MODEL_01d042efa4bb4275b044c101d641416c",
       "IPY_MODEL_5bd60f27249540629759b87e9af26f18"
      ],
      "layout": "IPY_MODEL_301ae1e92ed24dd4b1f8c6961e00c0ec"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
